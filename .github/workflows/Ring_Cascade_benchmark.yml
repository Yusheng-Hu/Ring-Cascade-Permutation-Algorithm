name: RCPA-vs-Heap-Comparison-Benchmark

on:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  # --- Stage 1: Benchmark Execution ---
  benchmark:
    name: Comparison (N=${{ matrix.n_factor }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        n_factor: [10, 11, 12, 13]

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Capture Raw CPU Data
      run: |
        # Capture raw data to files for Stage 2
        lscpu > raw_lscpu.txt
        head -n 20 /proc/cpuinfo > raw_cpuinfo.txt
        
        # Simple detection for vendor logic
        if grep -qi "AMD" raw_lscpu.txt || grep -qi "AMD" raw_cpuinfo.txt; then
          echo "VENDOR=AMD" >> $GITHUB_ENV
        else
          echo "VENDOR=INTEL" >> $GITHUB_ENV
        fi

    - name: Compile Source Files
      run: |
        g++ -O3 -std=c++11 -march=native -ffast-math \
        cpp/Ring_Cascade_Permutation_Algorithm.cpp -o rcpa_test -pthread
        
        g++ -O3 -march=native cpp/heap_perm.cpp -o heap_test -pthread

    - name: Run Performance Test
      run: |
        H_OUT=$(./heap_test ${{ matrix.n_factor }})
        H_TIME=$(echo "$H_OUT" | grep "EXECUTION_TIME:" | awk '{print $2}')
        
        R_OUT=$(./rcpa_test ${{ matrix.n_factor }})
        R_TIME=$(echo "$R_OUT" | grep "EXECUTION_TIME:" | awk '{print $2}')
        
        SPEEDUP=$(echo "scale=2; $H_TIME / $R_TIME" | bc)
        echo "N=${{ matrix.n_factor }}|H=$H_TIME|R=$R_TIME|S=$SPEEDUP" > res_${{ matrix.n_factor }}.txt

    - name: Upload Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: debug-info-${{ matrix.n_factor }}
        path: |
          res_${{ matrix.n_factor }}.txt
          raw_lscpu.txt
          raw_cpuinfo.txt

  # --- Stage 2: README Update & Raw Data Injection ---
  update-readme:
    name: Update README with Comparison Table
    needs: benchmark
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Download Artifacts
      uses: actions/download-artifact@v4
      with:
        path: results
        pattern: debug-info-*

    - name: Process Results and Inject Raw Info
      shell: python
      run: |
        import os, glob, re
        from datetime import datetime, timedelta

        vendor = os.environ.get('VENDOR', 'INTEL')
        start_m = f"[//]: # (RCPA_VS_HEAP_{vendor}_START)"
        end_m = f"[//]: # (RCPA_VS_HEAP_{vendor}_END)"
        
        # Load Raw Debug Data from the first available artifact
        debug_folder = glob.glob("results/debug-info-*")[0]
        with open(os.path.join(debug_folder, "raw_lscpu.txt"), "r") as f:
            raw_lscpu = f.read().strip()
        with open(os.path.join(debug_folder, "raw_cpuinfo.txt"), "r") as f:
            raw_cpuinfo = f.read().strip()

        # Simple extraction attempt for the Environment display
        cpu_model = "Unknown"
        for line in raw_lscpu.splitlines():
            if "Model name" in line or "处理器" in line:
                cpu_model = line.split(":", 1)[1].strip()
                break

        # Timestamps
        now_utc = datetime.utcnow()
        now_bj = now_utc + timedelta(hours=8)
        ts_utc = now_utc.strftime("%a %b %d %H:%M:%S %Y UTC")
        ts_bj = now_bj.strftime("%a %b %d %H:%M:%S %Y (UTC+8)")
        
        # Build Report
        report_lines = [
            f"**Last Run:** {ts_utc} / {ts_bj}",
            f"**Environment:** `{cpu_model}` (GitHub Actions Runner)",
            "",
            "",
            "| N | Heap's Algorithm (s) | RCPA (s) | Speedup (vs Heap) |",
            "|---|---|---|---|"
        ]
        
        # Collect Benchmark Data
        res_files = glob.glob("results/debug-info-*/res_*.txt")
        data_points = []
        for f in res_files:
            with open(f, 'r') as file:
                content = file.read().strip()
                match = re.search(r"N=(\d+)\|H=([\d.]+)\|R=([\d.]+)\|S=([\d.]+)", content)
                if match: data_points.append(match.groups())
        
        for n, h, r, s in sorted(data_points, key=lambda x: int(x[0])):
            report_lines.append(f"| {n} | {h} s | {r} s | **{s}x** |")

        new_content = "\n".join(report_lines)
        
        with open("README.md", "r", encoding="utf-8") as f:
            readme = f.read()
            
        if start_m in readme and end_m in readme:
            pattern = rf"{re.escape(start_m)}.*?{re.escape(end_m)}"
            updated_readme = re.sub(pattern, f"{start_m}\n\n{new_content}\n\n{end_m}", readme, flags=re.DOTALL)
            with open("README.md", "w", encoding="utf-8") as f:
                f.write(updated_readme)
        else:
            print(f"Error: Markers not found!")
            exit(1)

    - name: Commit and Push Changes
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add README.md
        git commit -m "docs: update benchmark with raw debug info [skip ci]" || exit 0
        git push origin main
