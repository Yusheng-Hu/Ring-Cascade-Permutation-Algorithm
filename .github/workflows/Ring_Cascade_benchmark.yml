name: RCPA-vs-Heap-Comparison-Benchmark

on:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  # --- Stage 1: Benchmark Execution ---
  benchmark:
    name: Comparison (N=${{ matrix.n_factor }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        n_factor: [10, 11, 12, 13]

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Detect CPU Architecture
      run: |
        # Capture raw outputs for debugging
        RAW_LSCPU=$(lscpu | grep -E 'Model name|处理器' | cut -d: -f2 | xargs || echo "N/A")
        RAW_PROC=$(grep -m 1 "model name" /proc/cpuinfo | cut -d: -f2 | xargs || echo "N/A")
        
        # Determine Vendor for marker selection
        if [[ "$RAW_LSCPU" == *"AMD"* || "$RAW_PROC" == *"AMD"* ]]; then 
          VENDOR="AMD"
        else 
          VENDOR="INTEL"
        fi
        
        # Exporting to GITHUB_ENV for the next stage
        echo "CPU_MODEL_LSCPU=$RAW_LSCPU" >> $GITHUB_ENV
        echo "CPU_MODEL_PROC=$RAW_PROC" >> $GITHUB_ENV
        echo "VENDOR=$VENDOR" >> $GITHUB_ENV

    - name: Compile Source Files
      run: |
        # Ensure path points to 'cpp/' directory
        g++ -O3 -std=c++11 -march=native -ffast-math \
        cpp/Ring_Cascade_Permutation_Algorithm.cpp -o rcpa_test -pthread
        
        g++ -O3 -march=native cpp/heap_perm.cpp -o heap_test -pthread

    - name: Run Performance Test
      run: |
        H_OUT=$(./heap_test ${{ matrix.n_factor }})
        H_TIME=$(echo "$H_OUT" | grep "EXECUTION_TIME:" | awk '{print $2}')
        
        R_OUT=$(./rcpa_test ${{ matrix.n_factor }})
        R_TIME=$(echo "$R_OUT" | grep "EXECUTION_TIME:" | awk '{print $2}')
        
        SPEEDUP=$(echo "scale=2; $H_TIME / $R_TIME" | bc)
        echo "N=${{ matrix.n_factor }}|H=$H_TIME|R=$R_TIME|S=$SPEEDUP" > res_${{ matrix.n_factor }}.txt

    - name: Upload Result Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: raw-res-${{ matrix.n_factor }}-${{ env.VENDOR }}
        path: res_${{ matrix.n_factor }}.txt

  # --- Stage 2: README Update & Debug Output ---
  update-readme:
    name: Update README with Comparison Table
    needs: benchmark
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Download Artifacts
      uses: actions/download-artifact@v4
      with:
        path: results
        pattern: raw-res-*

    - name: Process Results and Debug Info
      shell: python
      run: |
        import os, glob, re
        from datetime import datetime, timedelta

        # Get environmental info passed from Stage 1
        vendor = os.environ.get('VENDOR', 'INTEL')
        cpu_lscpu = os.environ.get('CPU_MODEL_LSCPU', 'N/A')
        cpu_proc = os.environ.get('CPU_MODEL_PROC', 'N/A')
        
        start_m = f"[//]: # (RCPA_VS_HEAP_{vendor}_START)"
        end_m = f"[//]: # (RCPA_VS_HEAP_{vendor}_END)"
        
        # Timestamps
        now_utc = datetime.utcnow()
        now_bj = now_utc + timedelta(hours=8)
        ts_utc = now_utc.strftime("%a %b %d %H:%M:%S %Y UTC")
        ts_bj = now_bj.strftime("%a %b %d %H:%M:%S %Y (UTC+8)")
        
        # Build Table and DEBUG Information
        report_lines = [
            f"**Last Run:** {ts_utc} / {ts_bj}",
            f"**Environment (lscpu):** `{cpu_lscpu}`",
            f"**Environment (procfs):** `{cpu_proc}`",
            "",
            "| N | Heap's Algorithm (s) | RCPA (s) | Speedup (vs Heap) |",
            "|---|---|---|---|"
        ]
        
        # Collect Data
        res_files = glob.glob("results/raw-res-*/res_*.txt")
        data_points = []
        for f in res_files:
            with open(f, 'r') as file:
                content = file.read().strip()
                match = re.search(r"N=(\d+)\|H=([\d.]+)\|R=([\d.]+)\|S=([\d.]+)", content)
                if match: data_points.append(match.groups())
        
        for n, h, r, s in sorted(data_points, key=lambda x: int(x[0])):
            report_lines.append(f"| {n} | {h} s | {r} s | **{s}x** |")

        new_content = "\n".join(report_lines)
        
        with open("README.md", "r", encoding="utf-8") as f:
            readme = f.read()
            
        if start_m in readme and end_m in readme:
            pattern = rf"{re.escape(start_m)}.*?{re.escape(end_m)}"
            updated_readme = re.sub(pattern, f"{start_m}\n\n{new_content}\n\n{end_m}", readme, flags=re.DOTALL)
            with open("README.md", "w", encoding="utf-8") as f:
                f.write(updated_readme)
        else:
            print(f"Error: Markers {start_m} / {end_m} not found!")
            exit(1)

    - name: Commit and Push Changes
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add README.md
        git commit -m "docs: update benchmark results with debug info [skip ci]" || exit 0
        git push origin
